{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2427ac87",
   "metadata": {},
   "source": [
    "<h1>언어 모델(Language Model)</h1>\n",
    ": 언어 모델(Language Model, LM)은 언어라는 현상을 모델링하고자 단어 시퀀스(또는 문장)에 확률을 할당하는 모델.<br>\n",
    "언어 모델을 만드는 방법<br>\n",
    "1. 통계를 이용한 방법<br>\n",
    ": 이전 단어들이 주어졌을 때 다음 단어를 예측하는 언어 모델<br>\n",
    "2. 인공 신경망을 이용한 방법<br>\n",
    ": 주어진 양쪽의 단어들로부터 가운데 비어있는 단어를 예측하는 언어 모델<br>\n",
    " - GPT<br>\n",
    " - BERT<br><br>\n",
    " \n",
    " 언어 모델링(Language Modeling) : 주어진 단어들로부터 아직 모르는 단어를 예측하는 작업<br><br>\n",
    "<h2>단어 시퀀스의 확률 할당</h2>\n",
    "언어 모델은 확률틀 통해 보다 적절한 문장 판단<br>\n",
    "a. 기계 번역(Machine Translation)<br>\n",
    ":    P(나는 버스를 탔다) > P(나는 버스를 태운다)<br><br>\n",
    "b. 오타 교정(Spell Correction)<br>\n",
    ":    P(달려갔다) > P(잘려갔다)<br><br>\n",
    "c. 음성 인식(Speech Recognition)<br>\n",
    ":    P(나는 메롱을 먹는다) < P(나는 메론을 먹는다)<br><br>\n",
    "\n",
    "<h2>주어진 이전 단어들로부터 다음 단어 예측하기</h2>\n",
    "A. 단어 시퀀스의 확률<br>\n",
    "하나의 단어를 w, 단어 시퀀스를 W라고 한다면 n개의 단어가 등장하는 단어 시퀀스 W의 확률<br>\n",
    "P(W)=P(w1, w2, w3, w4, ... , wn)<br>\n",
    "B. 다음 단어 등장 확률<br>\n",
    "n-1개의 단어가 나열된 상태에서 n번ㅉ째 단어의 확률<br>\n",
    "P(wn|w1, ... , wn-1) # | : 조건부 확률<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
